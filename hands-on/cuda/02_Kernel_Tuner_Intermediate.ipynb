{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y3BG43Gkw61"
      },
      "source": [
        "# Kernel Tuner Tutorial\n",
        "\n",
        "## Intermediate Hands-on\n",
        "\n",
        "In this hands-on we will look at three features of Kernel Tuner that have been recently introduced to you: **search space restrictions**, **caching**, and **output verification**.\n",
        "\n",
        "But first, if you have not done it already, it is time to install and import `kernel_tuner` and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TboeDlEAgqp0",
        "outputId": "d15e69dd-26c2-48a9-8565-85d4c6ccdfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kernel_tuner\n",
            "  Downloading kernel_tuner-1.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (4.23.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (2.2.2)\n",
            "Collecting python-constraint2<3.0.0,>=2.1.0 (from kernel_tuner)\n",
            "  Downloading python_constraint2-2.2.3-cp311-cp311-manylinux_2_35_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from kernel_tuner) (1.15.3)\n",
            "Collecting xmltodict (from kernel_tuner)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->kernel_tuner) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->kernel_tuner) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->kernel_tuner) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->kernel_tuner) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->kernel_tuner) (3.6.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->kernel_tuner) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->kernel_tuner) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->kernel_tuner) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->kernel_tuner) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->kernel_tuner) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->kernel_tuner) (4.13.2)\n",
            "Downloading kernel_tuner-1.1.3-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_constraint2-2.2.3-cp311-cp311-manylinux_2_35_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict, python-constraint2, kernel_tuner\n",
            "Successfully installed kernel_tuner-1.1.3 python-constraint2-2.2.3 xmltodict-0.14.2\n"
          ]
        }
      ],
      "source": [
        "%pip install kernel_tuner\n",
        "\n",
        "import numpy as np\n",
        "import kernel_tuner as kt\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSglXdizKW5"
      },
      "source": [
        "To work with these features we will use a matrix multiplication kernel.\n",
        "\n",
        "Matrix multiplication is one of the most well-known and widely-used linear algebra operations, and is frequently used to demonstrate the high-performance computing capabilities of GPUs. As such, matrix multiplication presents a familiar starting point for many GPU programmers. More information about matrix multiplication can be found on [Wikipedia](https://en.wikipedia.org/wiki/Matrix_multiplication).\n",
        "\n",
        "The following cell contains the code of a matrix multiply kernel using shared memory. The content of the cell is written to the `matmul_shared.cu` file, and you only need to execute the cell once as this hands-on does not require to change the implementation of the kernel.\n",
        "\n",
        "This kernel assumes that the width and height of the matrices `A`, `B`, and `C` is equal to `WIDTH`, which is known at compile time. Of course, you'll want a more flexible solution in reality, but this is just an example kernel to demonstrate how to use Kernel Tuner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JJRLQecvoc1_",
        "outputId": "e1cd3ac9-6491-4a1a-b26c-7fab711fa681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matmul_shared.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#define WIDTH 512\n",
        "\n",
        "__global__ void matmul_kernel(float *C, float *A, float *B) {\n",
        "\n",
        "    __shared__ float sA[block_size_y][block_size_x];\n",
        "    __shared__ float sB[block_size_y][block_size_x];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int x = blockIdx.x * block_size_x + tx;\n",
        "    int y = blockIdx.y * block_size_y + ty;\n",
        "\n",
        "    float sum = 0.0;\n",
        "    int k,kb;\n",
        "\n",
        "    for (k=0; k<WIDTH; k+=block_size_x) {\n",
        "        __syncthreads();\n",
        "        sA[ty][tx] = A[y*WIDTH+k+tx];\n",
        "        sB[ty][tx] = B[(k+ty)*WIDTH+x];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (kb=0; kb<block_size_x; kb++) {\n",
        "            sum += sA[ty][kb] * sB[kb][tx];\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "    C[y*WIDTH+x] = sum;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftZM8ogLzt71"
      },
      "source": [
        "Before running the code we need to allocate input and output matrices, and add some tuning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5K1BmJhdzuO2"
      },
      "outputs": [],
      "source": [
        "# matrix width needs to match the value in the kernel source\n",
        "problem_size = (512, 512)\n",
        "\n",
        "A = np.random.randn(*problem_size).astype(np.float32)\n",
        "B = np.random.randn(*problem_size).astype(np.float32)\n",
        "C = np.zeros_like(A)\n",
        "\n",
        "args = [C, A, B]\n",
        "\n",
        "tune_params = collections.OrderedDict()\n",
        "tune_params[\"block_size_x\"] = [2**i for i in range(0, 11)]\n",
        "tune_params[\"block_size_y\"] = [2**i for i in range(0, 11)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WuLDI7BlQ2c"
      },
      "source": [
        "It is now your turn to add some **search space restrictions**. You are free to add all the restrictions you want, but there is one in particular that is required for the kernel to produce correct results: the shape of the thread block needs to be **exactly** a square.\n",
        "\n",
        "Remember that restrictions are specified as either a Python list containing strings, each string being one restriction, or as a callable object that returns `True` if the configuration is valid and `False` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hTI0HEDkmHas"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 1: Define the required search space restriction for the matrix multiplication kernel\n",
        "restrict = [\"block_size_y==block_size_x\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9qQzbuBlWcf"
      },
      "source": [
        "To enable the **caching** of intermediate results during tuning, Kernel Tuner needs to know the name of the cache file. The name can be specified as a string, to which Kernel Tuner automatically adds the `.json` extension if not specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_R9F5guoaMAd"
      },
      "outputs": [],
      "source": [
        "# define a string containing the cache file name\n",
        "cache_name = \"my_cache_file.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT9NLyIrZiWl"
      },
      "source": [
        "Do not forget to pass the restrictions to the `tune_kernel` function and enable caching as documented in Kernel Tuner's [API](https://KernelTuner.github.io/kernel_tuner/stable/user-api.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LgrPl5Vc0cCe",
        "outputId": "6547e0cc-9a65-4223-f810-876236d2d2a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: Tesla T4\n",
            "Searchspace has 6 configurations after restrictions.\n",
            "block_size_x=1, block_size_y=1, time=50.751ms\n",
            "block_size_x=2, block_size_y=2, time=7.970ms\n",
            "block_size_x=4, block_size_y=4, time=1.419ms\n",
            "block_size_x=8, block_size_y=8, time=0.438ms\n",
            "block_size_x=16, block_size_y=16, time=0.285ms\n",
            "block_size_x=32, block_size_y=32, time=0.272ms\n",
            "best performing configuration:\n",
            "block_size_x=32, block_size_y=32, time=0.272ms\n",
            "Number of configurations: 6\n"
          ]
        }
      ],
      "source": [
        "if not restrict:\n",
        "    print(\"Error: you must first define a search space restriction! (Exercise 1)\")\n",
        "\n",
        "# Call the tuner with the restricted search space\n",
        "else:\n",
        "    results, env = kt.tune_kernel(\"matmul_kernel\", \"matmul_shared.cu\",\n",
        "                                  problem_size, args, tune_params, restrictions=restrict,\n",
        "                                  cache=cache_name, verbose=True, lang=\"cupy\")\n",
        "\n",
        "    print(f\"Number of configurations: {len(results)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WKhURhGmOnS"
      },
      "source": [
        "### Output verification\n",
        "\n",
        "There are times, like with this matrix multiplication kernel, when some tuning configurations may produce wrong results.\n",
        "\n",
        "It is important to catch this as soon as possible, and Kernel Tuner allows to pass to the `tune_kernel` function a reference answer to which the results produced by all configuration are compared against.\n",
        "\n",
        "The reference answer is a Python list that matches in size and order the argument list provided to the kernel (`args` in our case), with `None` for all elements for which a comparison is not needed. In case of working with floating point values, Kernel Tuner allows also to specify a tolerance value.\n",
        "\n",
        "Again refer to the [API](https://KernelTuner.github.io/kernel_tuner/stable/user-api.html) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bqdn4OYdmRI4"
      },
      "outputs": [],
      "source": [
        "# compute the reference result, e.g. by using NumPy\n",
        "reference = A.dot(B)\n",
        "\n",
        "# EXERCISE 2: Correctly construct the answer list required by Kernel Tuner\n",
        "answer = [reference, None,None]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are ready to call the tuner again with output verification enabled."
      ],
      "metadata": {
        "id": "qi-b2b2rGjvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not answer:\n",
        "    print(\"Error: you must first setup the answer list correctly! (Exercise 2)\")\n",
        "\n",
        "# Call the tuner with output verification enabled\n",
        "else:\n",
        "    results, env = kt.tune_kernel(\"matmul_kernel\", \"matmul_shared.cu\",\n",
        "                             problem_size, args, tune_params, restrictions=restrict,\n",
        "                             answer=answer, lang=\"cupy\", atol=1e-4)\n",
        "\n",
        "    print(f\"Number of configurations: {len(results)}\")"
      ],
      "metadata": {
        "id": "8zAZb6ThGicZ",
        "outputId": "9f0b2fc2-4894-4800-997e-f153dc7c42cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: Tesla T4\n",
            "block_size_x=1, block_size_y=1, time=50.734ms\n",
            "block_size_x=2, block_size_y=2, time=7.967ms\n",
            "block_size_x=4, block_size_y=4, time=1.422ms\n",
            "block_size_x=8, block_size_y=8, time=0.435ms\n",
            "block_size_x=16, block_size_y=16, time=0.284ms\n",
            "block_size_x=32, block_size_y=32, time=0.266ms\n",
            "best performing configuration:\n",
            "block_size_x=32, block_size_y=32, time=0.266ms\n",
            "Number of configurations: 6\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02-Kernel_Tuner-Intermediate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}